{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e99cd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     /Users/lizjohnson/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lizjohnson/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/lizjohnson/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/lizjohnson/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/lizjohnson/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import urllib.request, json\n",
    "import requests\n",
    "import urllib.parse\n",
    "import datetime\n",
    "import nltk\n",
    "nltk.download([\n",
    "        \"names\",\n",
    "        \"stopwords\",\n",
    "        \"averaged_perceptron_tagger\",\n",
    "        \"vader_lexicon\",\n",
    "        \"punkt\",])\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c0c738",
   "metadata": {},
   "source": [
    "### NYC Open Data:\n",
    "    \n",
    "SODA API Urls:\n",
    "\n",
    "* 311 Call Inquiries: `https://data.cityofnewyork.us/resource/wewp-mm3p.json`\n",
    "\n",
    " **Important Column Names:**\n",
    "\n",
    "   * uniqueid = 'UNIQUE_ID'\n",
    "   * cat_clnm = 'AGENCY_NAME'\n",
    "   * subcat_clnm = 'INQUIRY_NAME'\n",
    "   * subsubcat_clnm = 'BRIEF_DESCRIPTION'\n",
    "   * datetime_clnm = 'DATE_TIME'\n",
    "\n",
    "\n",
    "* 311 Web Inquiries: `https://data.cityofnewyork.us/resource/vwpc-kje2.json`\n",
    "\n",
    " **Important Column Names:**\n",
    "\n",
    "   * uniqueid = 'simple_id'\n",
    "   * cat_clnm = 'service_name'\n",
    "   * subcat_clnm = 'brief_description'\n",
    "   * subsubcat_clnm = 'detailed_description'\n",
    "   * datetime_clnm = 'updated_date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd655b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://data.cityofnewyork.us/resource/wewp-mm3p.json?$select=count(*)%20as%20count,AGENCY_NAME%20as%20cat,%20INQUIRY_NAME%20as%20subcat,%20BRIEF_DESCRIPTION%20as%20subsubcat&$where=DATE_TIME%20between%20'2019-01-01T00:00:00.000'%20and%20'2020-01-01T00:00:00.000'&$group=cat,subcat,subsubcat&$order=count%20DESC&$limit=500000\n"
     ]
    }
   ],
   "source": [
    "calls =  'https://data.cityofnewyork.us/resource/wewp-mm3p.json'\n",
    "\n",
    "uniqueid = 'UNIQUE_ID'\n",
    "cat_clnm = 'AGENCY_NAME'\n",
    "subcat_clnm = 'INQUIRY_NAME'\n",
    "subsubcat_clnm = 'BRIEF_DESCRIPTION'\n",
    "datetime_clnm = 'DATE_TIME'\n",
    "startdatetime = '2019-01-01T00:00:00.000'\n",
    "enddatetime =  '2020-01-01T00:00:00.000'\n",
    "\n",
    "query = (calls +'?'\n",
    "    \"$select=count(*) as count,%s as cat, %s as subcat, %s as subsubcat\"\n",
    "    \"&$where=%s between '\"+startdatetime+\"' and '\"+enddatetime+\"'\"\n",
    "    \"&$group=cat,subcat,subsubcat\"\n",
    "    \"&$order=count DESC\"\n",
    "    \"&$limit=500000\"\n",
    "    )%(cat_clnm,subcat_clnm,subsubcat_clnm,datetime_clnm)\n",
    "query = query.replace(\" \", \"%20\")\n",
    "print(query)\n",
    "response = urllib.request.urlopen(query)\n",
    "data = json.loads(response.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf779bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_comps = pd.DataFrame(data, columns = data[0].keys())\n",
    "call_comps.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86461bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(call_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8206ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(call_comps[call_comps['cat'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6cc316",
   "metadata": {},
   "outputs": [],
   "source": [
    "web = 'https://data.cityofnewyork.us/resource/vwpc-kje2.json'\n",
    "\n",
    "uniqueid = 'service_id'\n",
    "cat_clnm = 'service_name'\n",
    "subcat_clnm = 'brief_description'\n",
    "subsubcat_clnm = 'detailed_description'\n",
    "datetime_clnm = 'updated_date'\n",
    "startdatetime = '2019-01-01T00:00:00.000'\n",
    "enddatetime =  '2020-01-01T00:00:00.000'\n",
    "\n",
    "query = (web +'?'\n",
    "    \"$select=count(*) as count,%s as cat, %s as subcat, %s as subsubcat\"\n",
    "    \"&$where=%s between '\"+startdatetime+\"' and '\"+enddatetime+\"'\"\n",
    "    \"&$group=cat,subcat,subsubcat\"\n",
    "    \"&$order=count DESC\"\n",
    "    \"&$limit=500000\"\n",
    "    )%(cat_clnm,subcat_clnm,subsubcat_clnm,datetime_clnm)\n",
    "query = query.replace(\" \", \"%20\")\n",
    "print(query)\n",
    "response = urllib.request.urlopen(query)\n",
    "data = json.loads(response.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999b3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_comps = pd.DataFrame(data, columns = data[0].keys())\n",
    "web_comps.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comps = call_comps.append(web_comps)\n",
    "all_comps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_comps['combined_cats'] = call_comps['cat'].fillna('') \\\n",
    "                      .str.cat(call_comps['subcat'].fillna(''), sep=' ') \\\n",
    "                      .str.cat(call_comps['subsubcat'].fillna(''), sep=' ')\n",
    "\n",
    "call_comps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ce9202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean combined_cats column to prepare for NLTK processing\n",
    "#lowercase\n",
    "call_comps['combined_cats_lower'] = call_comps['combined_cats'].str.lower()\n",
    "#make list\n",
    "txt_ls = call_comps['combined_cats_lower'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803c1e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "\n",
    "tmp_list_unique = []\n",
    "\n",
    "for item in txt_ls:\n",
    "    \n",
    "    item = item.replace('sanitation', 'sanitation waste')\n",
    "    item = item.replace('parks', 'parks recreation')\n",
    "    item = item.replace('recreation', 'parks recreation')\n",
    "    item = item.replace('watr', 'water')\n",
    "    item = item.replace('wats', 'water')\n",
    "    item = item.replace('wrs', 'waste')\n",
    "    item = item.replace('<p>', ' ')\n",
    "    item = item.replace('<div>', ' ')\n",
    "    \n",
    "    item = item.replace('park maintenance', 'recreation and parks maintenance')\n",
    "    item = item.replace('park rules', 'recreation and parks rules')\n",
    "    item = item.replace('park equipment', 'recreation and parks equipment')\n",
    "    item = item.replace('park lawn', 'recreation and parks lawn')\n",
    "    item = item.replace('park programs', 'recreation and parks program')\n",
    "    item = item.replace('park light', 'recreation and parks light')\n",
    "    item = item.replace('park rangers', 'recreation and parks rangers')\n",
    "    item = item.replace('park surface', 'recreation and parks surface')\n",
    "    item = item.replace('rec and park', 'recreation and parks')\n",
    "    \n",
    "    item = item.replace('wildlife', 'wildlife animal')\n",
    "    item = item.replace('pigeon', 'pigeon animal')\n",
    "    item = item.replace('bats', 'bats animal')\n",
    "    item = item.replace('dog', 'dog animal')\n",
    "    item = item.replace('stray', 'stray animal')\n",
    "    item = item.replace('coyote', 'coyote animal')\n",
    "    item = item.replace('pot hole', 'pothole street')\n",
    "    item = item.replace('sinkhole', 'sinkhole pothole street')\n",
    "    \n",
    "    item = item.replace('parking', 'parking vehicles')\n",
    "    item = item.replace('bugs', 'public health bugs pest control')\n",
    "    itme = item.replace('mosquitoes', 'public health mosquito pest control')\n",
    "    itme = item.replace('mosquito', 'public health mosquito pest control')\n",
    "    itme = item.replace('roaches', 'public health roaches pest control')\n",
    "    item = item.replace('mice', 'public health rats rodent pest control')\n",
    "    item = item.replace('rodent', 'public health rodent rats pest control')\n",
    "    item = item.replace('dumping', 'dumping waste')\n",
    "    item = item.replace('illdump', 'illegal dumping waste')\n",
    "    item = item.replace('plmb', 'plumbming')\n",
    "    item = item.replace('haz', 'hazard')\n",
    "    item = item.replace('cons', 'construction')\n",
    "    item = item.replace('prmt', 'permit')\n",
    "    item = item.replace('cnflct', 'conflict')\n",
    "    item = item.replace('insp', 'inspection')\n",
    "    item = item.replace('litter', 'litter waste')\n",
    "    item = item.replace('isd', '')\n",
    "    item = item.replace('traum counseling', 'trauma counseling')\n",
    "    item = item.replace('dirty', 'dirty unsanitary')\n",
    "    item = item.replace('bldgmaint', 'building maintenance')\n",
    "    item = item.replace('derelict', 'abandonded')\n",
    "    item = item.replace('blighted', 'abandonded')\n",
    "    item = item.replace('vacant', 'abandonded')\n",
    "    item = item.replace('building code', 'inspection code enforcement violation')\n",
    "    item = item.replace('inspection', 'inspection code enforcement violation')\n",
    "    item = item.replace('code enforcement', 'inspection code enforcement violation')\n",
    "    item = item.replace('code violations', 'inspection code enforcement violation')\n",
    "    item = item.replace('housing violations', 'inspection code enforcement violation')\n",
    "    item = item.replace('property violations', 'inspection code enforcement violation')\n",
    "    item = item.replace('codes compliance', 'inspection code enforcement violation')\n",
    "    item = item.replace('transit', 'transit transportation')\n",
    "    item = item.replace('transportation', 'transit transportation')\n",
    "    item = item.replace('tenant', 'tenant housing rental')\n",
    "    item = item.replace('rental issues', 'tenant housing rental')\n",
    "    item = item.replace('brush', 'brush debris bulky')\n",
    "    item = item.replace('loose leaf', 'brush debris bulky')\n",
    "    item = item.replace('debris', 'brush debris bulky')\n",
    "    item = item.replace('stlight(s)', 'street light')\n",
    "    item = item.replace('collectn', 'bulky waste collection')\n",
    "    item = item.replace('household appliances', 'bulky waste collection')\n",
    "    item = item.replace('special collections', 'bulky waste collection')\n",
    "    item = item.replace('property maintenance', 'property maintenance building residential')\n",
    "    item = item.replace('building residential', 'property maintenance building residential')\n",
    "    item = item.replace('forestry', 'tree')\n",
    "    item = item.replace('national grid', 'electricity gas')\n",
    "    item = item.replace('bicycle', 'bike')\n",
    "    item = item.replace('botanical', 'tree')\n",
    "    item = item.replace('property', 'property building')\n",
    "    item = item.replace('pay station', 'pay station parking meter')\n",
    "    item = item.replace('general inquiry', 'general information')\n",
    "    item = item.replace('question', 'general information')\n",
    "    item = item.replace('general questions', 'general information')\n",
    "    item = item.replace('general request', 'general information')\n",
    "    item = item.replace('literature request', 'general information')\n",
    "    item = item.replace('program information', 'general information')\n",
    "    item = item.replace('information request', 'general information')\n",
    "    item = item.replace('records request', 'general information')\n",
    "    \n",
    "    item = item.replace('manhole', 'manhole drain')\n",
    "    item = item.replace('missed collection', 'missed collection waste')\n",
    "    item = item.replace('roadway', 'roads')\n",
    "    \n",
    "    item = item.replace('tax - ', 'tax taxpayer treasury')\n",
    "    item = item.replace('compliment', 'commendation')\n",
    "    \n",
    "    item = item.replace('constructiontruction', 'construction')\n",
    "    item = item.replace('contructionumber', 'construction')\n",
    "    \n",
    "    for number in ['1','2','3','4','5','6','7','8','9','0']:    \n",
    "        item = item.replace(number,'')\n",
    "    \n",
    "    #remove symbols exc NEW CODE INSERTED BY LIZ JOHNSON 11/15/22\n",
    "    symbols = \"!\\\"\\'#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in symbols:\n",
    "        item = np.char.replace(item, i, '')\n",
    "    \n",
    "    tmp_list_unique.append(str(item).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8893314",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp_list_unique[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df7d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "#remove stopwords\n",
    "tmp_list_unique = [[word for word in sentence.split() if word.lower() not in stopwords] for sentence in tmp_list_unique]\n",
    "#join split sentences back\n",
    "tmp_list_unique = [\" \".join(split_sentence) for split_sentence in tmp_list_unique]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec056aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp_list_unique[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8db965",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_comps['processed_comps'] = tmp_list_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ff87e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a function to calculate sentiment scores for each row in the dataframe\n",
    "def get_sentiment_scores(row):\n",
    "    # Use the VADER sentiment analyzer to get a sentiment score for the combined categories text\n",
    "    sentiment_scores = analyzer.polarity_scores(row['processed_comps'])\n",
    "    # Return the sentiment score dictionary\n",
    "    return sentiment_scores\n",
    "\n",
    "# Apply the function to each row in the dataframe and store the results in a new column\n",
    "call_comps['sentiment_scores'] = call_comps.apply(get_sentiment_scores, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e94fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_comps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21b5f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_comps[['neg','neu', 'pos', 'compound']] = call_comps['sentiment_scores'].apply(pd.Series)\n",
    "call_comps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d86f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean compound sentiment score for each category\n",
    "mean_sentiment_scores = call_comps.groupby('combined_cats')['sentiment_scores'].apply(lambda x: x.apply(lambda y: y['compound']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d049c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save outputs\n",
    "call_comps.to_csv('../Outputs/311calls_complaints_vadar_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874e4c6c",
   "metadata": {},
   "source": [
    "### Let's try and visualize the 311 inquiries' sentiment analysis results..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff0514a",
   "metadata": {},
   "source": [
    "# RESTART FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654e06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_comps = pd.read_csv('../Outputs/311calls_complaints_vadar_results.csv', index_col = 0)\n",
    "call_comps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0a71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values = call_comps[['cat','neg','neu','pos', 'compound']].groupby('cat').agg({'neg': 'mean', 'neu': 'mean', 'pos': 'mean', 'compound': 'mean'})\n",
    "median_values = call_comps[['cat','neg','neu','pos', 'compound']].groupby('cat').agg({'neg': 'median', 'neu': 'median', 'pos': 'median', 'compound': 'median'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f1b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values.sort_values(by = 'compound', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f397c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_values.sort_values(by = 'compound', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9724b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values.sort_values(by = 'compound').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c025d62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_values.sort_values(by = 'compound').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e4598",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_pos = list(mean_values.sort_values(by='compound', ascending=False)['compound'].head(5).index)\n",
    "top_5_neg = list(mean_values.sort_values(by='compound', ascending=False)['compound'].tail(5).index)\n",
    "print(top_5_pos,top_5_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117bcc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(call_comps[call_comps['cat'] == top_5_neg[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0072cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_comps[call_comps['cat'] == top_5_neg[-1]].sort_values(by = 'compound')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a37cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(call_comps[call_comps['cat'].isin(top_5_pos[0:2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da156b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_comps[call_comps['cat'].isin(top_5_pos[0:2])].sort_values(by = 'compound', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785fdfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(call_comps['compound'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77fca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ten most positive complaints\n",
    "pos_10 = call_comps.sort_values(by='compound', ascending=False).head(10)\n",
    "#ten most negative complaints\n",
    "neg_10 = call_comps.sort_values(by='compound', ascending=False).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2de1abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "neg_scores = pos_10['neg'][::-1]\n",
    "neu_scores = pos_10['neu'][::-1]\n",
    "pos_scores = pos_10['pos'][::-1]\n",
    "comps_scores = pos_10['compound'][::-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "ax.barh(np.arange(10), pos_scores, label='Positive', color='green')\n",
    "ax.barh(np.arange(10), neu_scores, left=pos_scores, label='Neutral', color='gray')\n",
    "ax.barh(np.arange(10), neg_scores, left=pos_scores+neu_scores, label='Negative', color='red')\n",
    "ax.set_xlabel('Sentiment Score')\n",
    "ax.set_title('Top 10 Positive Inquiries by Compound Score')\n",
    "ax.set_yticks(np.arange(10))\n",
    "# Wrap the text of each y-tick label onto multiple lines\n",
    "wrapped_labels = [textwrap.fill(label, width=75) for label in pos_10['combined_cats'][::-1]]\n",
    "ax.set_yticklabels(wrapped_labels, fontsize = 8)\n",
    "# Add label on top of each bar\n",
    "for i, score in enumerate(comps_scores):\n",
    "    ax.text(score+0.01, i, f'{score:.2f}', ha='left', va='center')\n",
    "legend = ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0))\n",
    "plt.savefig('../Outputs/Top_10_Positive_Compound_barh.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7306189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_scores = neg_10['neg']\n",
    "neu_scores = neg_10['neu']\n",
    "pos_scores = neg_10['pos']\n",
    "comps_scores = neg_10['compound']\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "ax.barh(np.arange(10), pos_scores, label='Positive', color='green')\n",
    "ax.barh(np.arange(10), neu_scores, left=pos_scores, label='Neutral', color='gray')\n",
    "ax.barh(np.arange(10), neg_scores, left=pos_scores+neu_scores, label='Negative', color='red')\n",
    "ax.set_xlabel('Sentiment Score')\n",
    "ax.set_title('Top 10 Negitive Inquiries by Compound Score')\n",
    "ax.set_yticks(np.arange(10))\n",
    "# Wrap the text of each y-tick label onto multiple lines\n",
    "wrapped_labels = [textwrap.fill(label, width=75) for label in neg_10['combined_cats']]\n",
    "ax.set_yticklabels(wrapped_labels, fontsize = 8)\n",
    "# Add label on top of each bar\n",
    "for i, score in enumerate(comps_scores):\n",
    "    ax.text(abs(score)+0.01, i, f'{score:.2f}', ha='right', va='center')\n",
    "legend = ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0))\n",
    "plt.savefig('../Outputs/Top_10_Negative_Compound_barh.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208f77df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look into neutrals\n",
    "len(call_comps[call_comps['compound'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1166c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(call_comps[call_comps['compound'] != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd351a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neu = call_comps[call_comps['compound'] == 0]\n",
    "neu['cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4c34b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "neu.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d774aaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neu[neu['neu'] != 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00866667",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_comps[call_comps['combined_cats_lower'].str.contains('homeless')].sort_values(by = 'compound').head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05471249",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_comps[call_comps['combined_cats_lower'].str.contains('noise')].sort_values(by = 'compound').head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59b4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_comps[call_comps['combined_cats_lower'].str.contains('graffiti')].sort_values(by = 'compound').head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff93a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
